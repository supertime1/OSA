{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "sleep_staging.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uR8fFRT-VRXp"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/OSA/blob/main/sleep_staging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qenih5OC1WGZ"
      },
      "source": [
        "#1.Import Dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6pBcyjuo_S9",
        "outputId": "36c14891-0e05-442c-c8c4-6bca1d2b6d44"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/a8/7d8a10345082d4807907a268016b52dfa869b0c412cd84aa1d1de86e1e39/mne-0.22.0-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.22.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF9Qp1QZL7co"
      },
      "source": [
        "import os\n",
        "import mne\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "import itertools\n",
        "import io\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Input, Add, Activation,\\\n",
        "MaxPooling1D,Dropout,Flatten,TimeDistributed,Bidirectional,Dense,LSTM, ZeroPadding1D, \\\n",
        "AveragePooling1D,GlobalMaxPooling1D, Concatenate, Permute, Dot, Multiply, RepeatVector,\\\n",
        "Lambda, Average, Softmax\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMfXVe3fac8"
      },
      "source": [
        "try:\r\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\r\n",
        "except ValueError:\r\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ivd9p141UMC"
      },
      "source": [
        "#2.Process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR8fFRT-VRXp"
      },
      "source": [
        "##2.1 Local preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6ZHOcPL7c2"
      },
      "source": [
        "def load_data(file_path, sf=128, epoch_duration=30):\n",
        "\n",
        "    ecg_samples = []\n",
        "    ecg_labels = []\n",
        "    total_epoches = 0\n",
        "    \n",
        "    for signal_file in glob.glob(file_path + '*[0-9].edf'):\n",
        "        \n",
        "        ecg_epoches = []\n",
        "        \n",
        "        data = mne.io.read_raw_edf(signal_file)\n",
        "        ecg_ch = [i for i, v in enumerate(data.info.ch_names) if v == 'ECG']\n",
        "        ecg_signal = data.get_data()[ecg_ch[0]]\n",
        "        \n",
        "        num_of_sample_per_epoch = sf * epoch_duration\n",
        "        num_of_epoches = len(ecg_signal) // (num_of_sample_per_epoch)\n",
        "        total_epoches += num_of_epoches\n",
        "        \n",
        "        print(f'{signal_file[-12:]} has {num_of_epoches} epoches')\n",
        "\n",
        "        for i in range(num_of_epoches):\n",
        "            ecg_epoch = ecg_signal[i*num_of_sample_per_epoch : (i+1)*num_of_sample_per_epoch]\n",
        "            ecg_epoches.append(ecg_epoch)\n",
        "        ecg_samples.append(ecg_epoches)\n",
        "    \n",
        "    for label_file in glob.glob(file_path + '*stage.txt'):\n",
        "        print(f'reading {label_file}')\n",
        "        ecg_labels.append(np.loadtxt(label_file))\n",
        "        \n",
        "    assert len(ecg_samples) == len(ecg_labels)\n",
        "\n",
        "    for i in range(len(ecg_samples)):\n",
        "        new_length = len(ecg_labels[i])\n",
        "        ecg_samples[i] = ecg_samples[i][:new_length]\n",
        "    \n",
        "    return ecg_samples, ecg_labels, total_epoches\n",
        "\n",
        "fp = \"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/\"\n",
        "ecg_samples, ecg_labels, total_epoches = load_data(fp, 128, 30)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "tcCZ0XlUPpOQ",
        "outputId": "6e79b8e9-312c-46ac-d244-d62681898476"
      },
      "source": [
        "with open(\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl\", \"wb\") as fp:\r\n",
        "    pickle.dump(ecg_samples, fp)\r\n",
        "\r\n",
        "with open(\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_labels.pkl\", \"wb\") as fp:\r\n",
        "    pickle.dump(ecg_labels, fp)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-999fb8c11cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_labels.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyIcQ2ThVVj5"
      },
      "source": [
        "##2.2 Load data from Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rScUZtnMVaAj",
        "outputId": "02ec62c8-ebd1-4f9d-a77a-c3b4fd9a5a7e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "file_path = '/content/drive/MyDrive/osa/ecg_samples.pkl'\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/osa/ecg_samples.pkl', \"rb\") as fp:\r\n",
        "    ecg_samples = pickle.load(fp)\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/osa/ecg_labels.pkl', \"rb\") as fp:\r\n",
        "    ecg_labels = pickle.load(fp)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMXE-6lL7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e50ed6-3120-4574-92d3-d71b31ab731e"
      },
      "source": [
        "# split by patient id \r\n",
        "def split_data(ecg_samples, ecg_labels, train_ratio, test_ratio):\r\n",
        "    test_num = round(len(ecg_samples) * test_ratio)\r\n",
        "    train_num = round((len(ecg_samples) - test_num) * train_ratio)\r\n",
        "    val_num = len(ecg_samples) - test_num - train_num\r\n",
        "\r\n",
        "    np.random.seed(seed=7)\r\n",
        "    np.random.shuffle(ecg_samples)\r\n",
        "    train_samples = ecg_samples[:train_num]\r\n",
        "    val_samples = ecg_samples[train_num:train_num+val_num]\r\n",
        "    test_samples = ecg_samples[-test_num:]\r\n",
        "\r\n",
        "    np.random.seed(seed=7)\r\n",
        "    np.random.shuffle(ecg_labels)\r\n",
        "    train_labels = ecg_labels[:train_num]\r\n",
        "    val_labels = ecg_labels[train_num:train_num+val_num]\r\n",
        "    test_labels = ecg_labels[-test_num:]\r\n",
        "\r\n",
        "    return train_samples, train_labels, val_samples, val_labels, test_samples, test_labels \r\n",
        "\r\n",
        "train_samples, train_labels, val_samples, val_labels, test_samples, test_labels = split_data(ecg_samples, ecg_labels, 0.8, 0.12)\r\n",
        "print(f'There are {len(train_samples)} subjects in training dataset')\r\n",
        "print(f'There are {len(val_samples)} subjects in validation dataset')\r\n",
        "print(f'There are {len(test_samples)} subjects in testing dataset')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 18 subjects in training dataset\n",
            "There are 4 subjects in validation dataset\n",
            "There are 3 subjects in testing dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liakZ4jYL7c7"
      },
      "source": [
        "def preprocess_data(num_epoch, epoch_duration, sf, ecg_samples, ecg_labels, oversample=True):\n",
        "    \"\"\"\n",
        "    preprocess data with the matched dimension for training\n",
        "    [num_epoch, 30*sampling_frequency, 1]\n",
        "\n",
        "    params:\n",
        "    epoch - number of epoches for each training sample\n",
        "    sf - sampling frequency of ECG signal\n",
        "    file_path - file path of raw EDF file\n",
        "    \"\"\"\n",
        "    model_signal_input = []\n",
        "    model_label_input = []\n",
        "\n",
        "    num_of_sample_per_epoch = sf * epoch_duration\n",
        "\n",
        "    for i in range(len(ecg_samples)):\n",
        "        \n",
        "        if oversample:\n",
        "            overlap = int(0.8 * num_epoch)\n",
        "            for j in range(len(ecg_samples[i])):\n",
        "                signal_segment = np.asarray(ecg_samples[i][j*(num_epoch - overlap): j*(num_epoch - overlap) + num_epoch])\n",
        "                if len(signal_segment) == num_epoch:\n",
        "                    new_signal_seg = np.reshape(signal_segment, (num_epoch, num_of_sample_per_epoch, 1))\n",
        "                    model_signal_input.append(new_signal_seg)\n",
        "                \n",
        "                # apply to labels as well\n",
        "                label_segment = np.asarray(ecg_labels[i][j*(num_epoch - overlap): j*(num_epoch - overlap) + num_epoch])\n",
        "                if len(label_segment) == num_epoch:\n",
        "                    model_label_input.append(label_segment)\n",
        "        \n",
        "        else:\n",
        "            for j in range(len(ecg_samples[i])):\n",
        "                signal_segment = np.asarray(ecg_samples[i][j*num_epoch: (j+1)*num_epoch]) \n",
        "                if len(signal_segment) == num_epoch:\n",
        "                    new_signal_seg = np.reshape(signal_segment, (num_epoch, num_of_sample_per_epoch, 1))\n",
        "                    model_signal_input.append(new_signal_seg)\n",
        "\n",
        "                # apply to labels as well\n",
        "                label_segment = np.asarray(ecg_labels[i][j*num_epoch: (j+1)*num_epoch])\n",
        "                if len(label_segment) == num_epoch:\n",
        "                    model_label_input.append(label_segment)\n",
        "        \n",
        "    print(f'shape of processed signal data: {np.asarray(model_signal_input).shape}')\n",
        "    print(f'shape of processed label data: {np.asarray(model_label_input).shape}')\n",
        "\n",
        "    return np.asarray(model_signal_input), np.asarray(model_label_input)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DyRhHbEyoT4",
        "outputId": "78480ed6-22dc-488d-9d46-868e0514e08e"
      },
      "source": [
        "def helper(samples, labels):\r\n",
        "    for i in range(len(samples)):\r\n",
        "        print(f'{len(samples[i])}, {len(labels[i])}')\r\n",
        "\r\n",
        "helper(ecg_samples, ecg_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "882, 882\n",
            "768, 768\n",
            "774, 774\n",
            "789, 789\n",
            "826, 826\n",
            "711, 711\n",
            "864, 864\n",
            "752, 752\n",
            "916, 916\n",
            "748, 748\n",
            "893, 893\n",
            "925, 925\n",
            "908, 908\n",
            "913, 913\n",
            "721, 721\n",
            "811, 811\n",
            "787, 787\n",
            "900, 900\n",
            "822, 822\n",
            "907, 907\n",
            "861, 861\n",
            "808, 808\n",
            "838, 838\n",
            "813, 813\n",
            "852, 852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_sRNpmNbsjB",
        "outputId": "ae0441a5-a18e-4fbe-955a-f17a7ab67385"
      },
      "source": [
        "train_signal_input, train_label_input = preprocess_data(100, 30, 128, train_samples, train_labels, oversample=True)\r\n",
        "val_signal_input, val_label_input = preprocess_data(100, 30, 128, val_samples, val_labels, oversample=False)\r\n",
        "test_signal_input, test_label_input = preprocess_data(100, 30, 128, test_samples, test_labels, oversample=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of processed signal data: (665, 100, 3840, 1)\n",
            "shape of processed label data: (665, 100)\n",
            "shape of processed signal data: (33, 100, 3840, 1)\n",
            "shape of processed label data: (33, 100)\n",
            "shape of processed signal data: (24, 100, 3840, 1)\n",
            "shape of processed label data: (24, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o362XJUmsMHa",
        "outputId": "8a256567-1703-48d1-b805-53ce9235d1eb"
      },
      "source": [
        "def print_label(label_input):\r\n",
        "    print(f'There are {len(label_input[label_input == 0])} wake labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 1])} REM labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 2])} Stage_1 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 3])} Stage_2 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 4])} Stage_3 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 5])} Stage_4 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 6])} Artifact labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 7])} Indeterminate labels \\n')\r\n",
        "\r\n",
        "print_label(train_label_input)\r\n",
        "print_label(val_label_input)\r\n",
        "print_label(test_label_input)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 13848 wake labels\n",
            "There are 9390 REM labels\n",
            "There are 11829 Stage_1 labels\n",
            "There are 23229 Stage_2 labels\n",
            "There are 2170 Stage_3 labels\n",
            "There are 5971 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n",
            "There are 723 wake labels\n",
            "There are 423 REM labels\n",
            "There are 573 Stage_1 labels\n",
            "There are 1048 Stage_2 labels\n",
            "There are 103 Stage_3 labels\n",
            "There are 430 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n",
            "There are 252 wake labels\n",
            "There are 492 REM labels\n",
            "There are 187 Stage_1 labels\n",
            "There are 1007 Stage_2 labels\n",
            "There are 115 Stage_3 labels\n",
            "There are 347 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBhTjlajO0JY"
      },
      "source": [
        "def join_labels(label_input):\r\n",
        "    for i in range(len(label_input)):\r\n",
        "        label_input[label_input > 1] = 2\r\n",
        "    print(f'There are {len(label_input[label_input == 0])} wake labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 1])} REM labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 2])} NREM labels \\n')\r\n",
        "    return label_input"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfBTo1DySxHh",
        "outputId": "d595f3a2-56ca-41ac-bbc2-54438f5d8e26"
      },
      "source": [
        "train_label_input_join = join_labels(train_label_input)\r\n",
        "val_label_input_join = join_labels(val_label_input)\r\n",
        "test_label_input_join = join_labels(test_label_input)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 13848 wake labels\n",
            "There are 9390 REM labels\n",
            "There are 43262 NREM labels \n",
            "\n",
            "There are 723 wake labels\n",
            "There are 423 REM labels\n",
            "There are 2154 NREM labels \n",
            "\n",
            "There are 252 wake labels\n",
            "There are 492 REM labels\n",
            "There are 1656 NREM labels \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "yTssoK6VBU5N",
        "outputId": "d73cf50d-5e40-44e7-c870-3378312d3b40"
      },
      "source": [
        "train_label_input_join"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-1f72f78713ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label_input_join\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XeavEnYttea"
      },
      "source": [
        "def oversample_label(train_signal_input, train_label_input_join):\r\n",
        "    os_train_signal_input = []\r\n",
        "    os_train_label_input_join = []\r\n",
        "    \r\n",
        "    for i in range(len(train_label_input_join)):\r\n",
        "        if len(train_label_input_join[i][train_label_input_join[i] == 2]) > 50:\r\n",
        "            np.append(train_signal_input, train_signal_input[i])\r\n",
        "            np.append(train_label_input_join, train_label_input_join[i])\r\n",
        "    \r\n",
        "    print(f'There are {len(train_label_input_join[train_label_input_join == 0])} wake labels')\r\n",
        "    print(f'There are {len(train_label_input_join[train_label_input_join == 1])} REM labels')\r\n",
        "    print(f'There are {len(train_label_input_join[train_label_input_join == 2])} NREM labels \\n')\r\n",
        "\r\n",
        "    return train_signal_input, train_label_input_join"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3dPkbW9vRhS"
      },
      "source": [
        "train_signal_input, train_label_input_join = oversample_label(train_signal_input, train_label_input_join)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcFDcYX61O72"
      },
      "source": [
        "#3.Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGPS_ab6z1li"
      },
      "source": [
        "##3.1 TFDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVnqfV5E2MfB"
      },
      "source": [
        "batch_size = 8\r\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_signal_input, train_label_input_join))\r\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_signal_input, val_label_input_join))\r\n",
        "train_dataset = train_dataset.cache()\r\n",
        "train_dataset = train_dataset.shuffle(512).repeat().batch(batch_size, drop_remainder=True)\r\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "val_dataset = val_dataset.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvRMtVPTyE5"
      },
      "source": [
        "##3.2 Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr7CnSvMTqvF"
      },
      "source": [
        "## tensorboard callback\r\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "\r\n",
        "## checkpoint callback\r\n",
        "filepath = os.path.join(\"models\",  \"test-oversample-128Hz-{epoch:02d}-{loss:.4f}\")\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\r\n",
        "\r\n",
        "## early stop\r\n",
        "def decay(epoch):\r\n",
        "    if epoch < 50:\r\n",
        "        return 1e-3\r\n",
        "    elif 50 <= epoch < 150:\r\n",
        "        return 1e-4\r\n",
        "    else:\r\n",
        "        return 1e-5\r\n",
        "\r\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\r\n",
        "\r\n",
        "## learning rate decay callback\r\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)\r\n",
        "\r\n",
        "callbacks_list = [tensorboard_callback, checkpoint, early_stop, lr_schedule]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4t-6PrNT1I5"
      },
      "source": [
        "##3.3 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxDhnq-R2AOW"
      },
      "source": [
        "###3.3.1 CNN+LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltJxzYIr3i3v"
      },
      "source": [
        "def cnn_1d(input_shape=None, dropout=0.2):\r\n",
        "    \r\n",
        "    x_input = Input(shape=input_shape)\r\n",
        "    x = Conv1D(64, 21, strides=5, activation='relu')(x_input)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 2nd Conv1D\r\n",
        "    x = Conv1D(128, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 3rd Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 4th Conv1D\r\n",
        "    x = Conv1D(512, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 5th Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    # Full connection layer\r\n",
        "    out = Flatten()(x)\r\n",
        "\r\n",
        "    model = Model(x_input, out, name='cnn_1d_layer')\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qU6oB2U5Nvw",
        "outputId": "82489b63-d542-4254-c3f1-e9f4a09865fa"
      },
      "source": [
        "def cnn_lstm(input_shape=(100,3840,1), classes=3):\r\n",
        "    cnn = cnn_1d((3840,1))\r\n",
        "    x_input = Input(shape=input_shape)\r\n",
        "    x = TimeDistributed(cnn)(x_input)\r\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\r\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\r\n",
        "    out = TimeDistributed(Dense(classes))(x)\r\n",
        "    model = Model(x_input, out, name='cnn_lstm')\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "model = cnn_lstm(input_shape=(100,3840,1), classes=3)\r\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 100, 3840, 1)]    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 100, 10240)        1522944   \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 100, 128)          5276160   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 100, 64)           41216     \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 100, 3)            195       \n",
            "=================================================================\n",
            "Total params: 6,840,515\n",
            "Trainable params: 6,838,083\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHvDHOP02EkZ"
      },
      "source": [
        "###3.3.2 Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bllwdvrx2HWW"
      },
      "source": [
        "def one_step_attention(a, s_prev): \r\n",
        "    \"\"\"\r\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\r\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\r\n",
        "\r\n",
        "    Arguments:\r\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\r\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    context -- context vector, input of the next (post-attention) LSTM cell\r\n",
        "    \"\"\"\r\n",
        "    s_prev = RepeatVector(Tx)(s_prev)\r\n",
        "    concat = Concatenate(axis=-1)([a, s_prev])\r\n",
        "    e = Dense(10, activation = \"tanh\")(concat)\r\n",
        "    energies = Dense(1, activation = \"relu\")(e)\r\n",
        "    alphas = tf.nn.softmax(energies,axis=1)\r\n",
        "    context = Dot(axes = 1)([alphas,a])\r\n",
        "\r\n",
        "    return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFuGyAkV2_dy"
      },
      "source": [
        "def Resnet18_Attention(Tx, Ty, n_a, n_s, output_size, input_image_size):\r\n",
        "\r\n",
        "    X_input = Input(shape = (Tx, input_image_size, 1))\r\n",
        "\r\n",
        "    #define Resnet-18 \r\n",
        "    X = TimeDistributed(cnn_1d)(X_input)\r\n",
        "\r\n",
        "    s0 = Input(shape = (n_s, ), name = 's0')\r\n",
        "    c0 = Input(shape = (n_s, ), name = 'c0')\r\n",
        "    s = s0\r\n",
        "    c = c0\r\n",
        "\r\n",
        "    #Initialize empty list of outputs\r\n",
        "    outputs = []\r\n",
        "\r\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\r\n",
        "\r\n",
        "    for t in range(Ty):\r\n",
        "    context = one_step_attention(a, s)\r\n",
        "    s, _, c = LSTM(n_s, return_state = True)(context, initial_state = [s, c])\r\n",
        "    out = Dense(output_size)(s)\r\n",
        "    #act = tf.nn.softmax(out, axis=1)\r\n",
        "    outputs.append(out)\r\n",
        "\r\n",
        "    outputs = Average()(outputs)\r\n",
        "    model = Model(inputs = (X_input, s0, c0), outputs = outputs)\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kbNKcqp16t1"
      },
      "source": [
        "##3.4 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhi6yWq-QSc"
      },
      "source": [
        "class CustomizedLoss(tf.keras.losses.Loss):\r\n",
        "    def compute_loss(self, logits, positions):\r\n",
        "        one_hot_positions = tf.one_hot(\r\n",
        "            int(positions), depth=3)\r\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\r\n",
        "        #weight = np.asarray([4,4,1])\r\n",
        "        loss = -tf.reduce_mean(\r\n",
        "            tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\r\n",
        "        return loss\r\n",
        "    \r\n",
        "    def call(self, y_true, y_pred):\r\n",
        "        loss = self.compute_loss(y_pred, y_true)\r\n",
        "        return loss"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFQivnnfhnfd"
      },
      "source": [
        "###3.4.1 Train with distributed TPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyM3gkryf8bg"
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\r\n",
        "    \r\n",
        "    model = cnn_lstm(input_shape=(100,3840,1), classes=3)\r\n",
        "\r\n",
        "    ## early stop\r\n",
        "    def decay(epoch):\r\n",
        "        if epoch < 50:\r\n",
        "            return 1e-4\r\n",
        "        elif 50 <= epoch < 150:\r\n",
        "            return 1e-5\r\n",
        "        else:\r\n",
        "            return 1e-6\r\n",
        "\r\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\r\n",
        "\r\n",
        "    ## learning rate decay callback\r\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)\r\n",
        "\r\n",
        "    callbacks_list = [early_stop, lr_schedule]\r\n",
        "\r\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\r\n",
        "              metrics=['accuracy'])\r\n",
        "    \r\n",
        "    history = model.fit(train_dataset,\r\n",
        "                        epochs=100,\r\n",
        "                        steps_per_epoch=len(train_signal_input)//batch_size,\r\n",
        "                        verbose=1,\r\n",
        "                        validation_data=val_dataset,\r\n",
        "                        validation_steps=len(val_signal_input)//batch_size,\r\n",
        "                        callbacks=callbacks_list,\r\n",
        "                        class_weight={0:4,1:4,2:1}\r\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUee80JIhjyY"
      },
      "source": [
        "###3.4.2 Train with single TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsdPxG-S4u6W"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "              loss=CustomizedLoss(),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkCRBVpfyoBs"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTUeyZ1hSNhf"
      },
      "source": [
        "from tensorboard import notebook\r\n",
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "VSaqMKILK74W",
        "outputId": "5e1f60ff-7b78-491c-da3b-606ebcc945bf"
      },
      "source": [
        "model.fit(train_dataset,\r\n",
        "          epochs=100,\r\n",
        "          steps_per_epoch=len(train_signal_input)//batch_size,\r\n",
        "          verbose=1,\r\n",
        "          validation_data=val_dataset,\r\n",
        "          validation_steps=len(val_signal_input)//batch_size,\r\n",
        "          callbacks=callbacks_list\r\n",
        "          )"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " 1/83 [..............................] - ETA: 12:59 - loss: 1.0956 - accuracy: 0.3750WARNING:tensorflow:Trace already enabled\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AlreadyExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-6e39561d4fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_signal_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m-> 1099\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \"\"\"\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_begin_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;34m\"\"\"Helper function for `on_*_batch_begin` methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'on_{mode}_batch_begin'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_train_batch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_start_trace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_start_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2345\u001b[0m     \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2346\u001b[0;31m     \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2347\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_tracing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/profiler_v2.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(logdir, options)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_profiler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       raise errors.AlreadyExistsError(None, None,\n\u001b[0;32m--> 116\u001b[0;31m                                       'Another profiler is running.')\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0m_profiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_profiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfilerSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAlreadyExistsError\u001b[0m: Another profiler is running."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgz_Nsz5sCfg"
      },
      "source": [
        "#4.Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ASNC6pT0m-A"
      },
      "source": [
        "# make predcitions\r\n",
        "val_pred_raw = model.predict(val_signal_input)\r\n",
        "val_pred = np.argmax(val_pred_raw, axis=-1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nCyuTB0BpO"
      },
      "source": [
        "##4.1 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY78rgfRsSTI"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names, normalize=False):\r\n",
        "    \"\"\"\r\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\r\n",
        "\r\n",
        "    Args:\r\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\r\n",
        "       class_names (array, shape = [n]): String names of the integer classes\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    figure = plt.figure(figsize=(8, 8))\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\r\n",
        "    plt.title(\"Confusion matrix\")\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(class_names))\r\n",
        "    plt.xticks(tick_marks, class_names)\r\n",
        "    plt.yticks(tick_marks, class_names)\r\n",
        "    plt.ylim(bottom=-0.5, top=2.5)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\r\n",
        "\r\n",
        "    # Use white text if squares are dark; otherwise black.\r\n",
        "    threshold = cm.max() / 1.5\r\n",
        "\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\r\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "Ga9jFfrBvJvk",
        "outputId": "ffb6b0ce-2490-45e3-c883-4b8e8fa14cdf"
      },
      "source": [
        "class_names = ['Wake','REM','NREM']\r\n",
        "cm = sklearn.metrics.confusion_matrix(val_label_input_join.flatten(), val_pred.flatten())\r\n",
        "plot_confusion_matrix(cm, class_names=class_names, normalize=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1U84UqH0FHd"
      },
      "source": [
        "##4.2 Cohen’s kappa coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdcd9LD-0Wob",
        "outputId": "7c990ab4-1b2f-421a-8dee-687a529b7434"
      },
      "source": [
        "sklearn.metrics.cohen_kappa_score(val_label_input_join.flatten(), val_pred.flatten())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28901251808963335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsgNnBoI0338"
      },
      "source": [
        "##4.3 Clinical parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SawPaKLS0-mD"
      },
      "source": [
        "# total sleep time\r\n",
        "# sleep efficiency\r\n",
        "# sleep stage percentage\r\n",
        "# AHI"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}