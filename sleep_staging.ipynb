{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "sleep_staging.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uR8fFRT-VRXp"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/OSA/blob/main/sleep_staging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qenih5OC1WGZ"
      },
      "source": [
        "#1.Import Dependency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6pBcyjuo_S9",
        "outputId": "0b8cd347-c1ae-41ac-abab-47ea4f29e907"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/a8/7d8a10345082d4807907a268016b52dfa869b0c412cd84aa1d1de86e1e39/mne-0.22.0-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.22.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF9Qp1QZL7co"
      },
      "source": [
        "import os\n",
        "import mne\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "import itertools\n",
        "import io\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Input, Add, Activation,\\\n",
        "MaxPooling1D,Dropout,Flatten,TimeDistributed,Bidirectional,Dense,LSTM, ZeroPadding1D, \\\n",
        "AveragePooling1D,GlobalMaxPooling1D, Concatenate, Permute, Dot, Multiply, RepeatVector,\\\n",
        "Lambda, Average, Softmax, Reshape\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGh3-bNv4ChP"
      },
      "source": [
        "###TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuMfXVe3fac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a49076-37d8-4b8e-a31c-3d50deb51f60"
      },
      "source": [
        "try:\r\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\r\n",
        "except ValueError:\r\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.78.210.250:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.210.250:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.210.250:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UObAIRxo4Elr"
      },
      "source": [
        "###GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN6YFa203lH7",
        "outputId": "8083f728-5f43-4508-d9be-95b695bac9e3"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ivd9p141UMC"
      },
      "source": [
        "#2.Process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR8fFRT-VRXp"
      },
      "source": [
        "##2.1 Local preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI6ZHOcPL7c2"
      },
      "source": [
        "def load_data(file_path, sf=128, epoch_duration=30):\n",
        "\n",
        "    ecg_samples = []\n",
        "    ecg_labels = []\n",
        "    total_epoches = 0\n",
        "    \n",
        "    for signal_file in glob.glob(file_path + '*[0-9].edf'):\n",
        "        \n",
        "        ecg_epoches = []\n",
        "        \n",
        "        data = mne.io.read_raw_edf(signal_file)\n",
        "        ecg_ch = [i for i, v in enumerate(data.info.ch_names) if v == 'ECG']\n",
        "        ecg_signal = data.get_data()[ecg_ch[0]]\n",
        "        \n",
        "        num_of_sample_per_epoch = sf * epoch_duration\n",
        "        num_of_epoches = len(ecg_signal) // (num_of_sample_per_epoch)\n",
        "        total_epoches += num_of_epoches\n",
        "        \n",
        "        print(f'{signal_file[-12:]} has {num_of_epoches} epoches')\n",
        "\n",
        "        for i in range(num_of_epoches):\n",
        "            ecg_epoch = ecg_signal[i*num_of_sample_per_epoch : (i+1)*num_of_sample_per_epoch]\n",
        "            ecg_epoches.append(ecg_epoch)\n",
        "        ecg_samples.append(ecg_epoches)\n",
        "    \n",
        "    for label_file in glob.glob(file_path + '*stage.txt'):\n",
        "        print(f'reading {label_file}')\n",
        "        ecg_labels.append(np.loadtxt(label_file))\n",
        "        \n",
        "    assert len(ecg_samples) == len(ecg_labels)\n",
        "\n",
        "    for i in range(len(ecg_samples)):\n",
        "        new_length = len(ecg_labels[i])\n",
        "        ecg_samples[i] = ecg_samples[i][:new_length]\n",
        "    \n",
        "    return ecg_samples, ecg_labels, total_epoches\n",
        "\n",
        "fp = \"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/\"\n",
        "ecg_samples, ecg_labels, total_epoches = load_data(fp, 128, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "tcCZ0XlUPpOQ",
        "outputId": "290e7d81-2eb9-40be-c792-6ae0e196bdd9"
      },
      "source": [
        "with open(\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl\", \"wb\") as fp:\r\n",
        "    pickle.dump(ecg_samples, fp)\r\n",
        "\r\n",
        "with open(\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_labels.pkl\", \"wb\") as fp:\r\n",
        "    pickle.dump(ecg_labels, fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-999fb8c11cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_labels.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/57lzhang.US04WW4008/Downloads/ucd/files/processed_data/ecg_samples.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyIcQ2ThVVj5"
      },
      "source": [
        "##2.2 Load data from Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rScUZtnMVaAj",
        "outputId": "8124a49f-8b03-4b11-e7a7-20e7c175d08c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "file_path = '/content/drive/MyDrive/osa/ecg_samples.pkl'\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/osa/ecg_samples.pkl', \"rb\") as fp:\r\n",
        "    ecg_samples = pickle.load(fp)\r\n",
        "\r\n",
        "with open('/content/drive/MyDrive/osa/ecg_labels.pkl', \"rb\") as fp:\r\n",
        "    ecg_labels = pickle.load(fp)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uMXE-6lL7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d77e4f-028e-4cbd-c6c5-1edbdc869575"
      },
      "source": [
        "# split by patient id \r\n",
        "def split_data(ecg_samples, ecg_labels, train_ratio, test_ratio):\r\n",
        "    test_num = round(len(ecg_samples) * test_ratio)\r\n",
        "    train_num = round((len(ecg_samples) - test_num) * train_ratio)\r\n",
        "    val_num = len(ecg_samples) - test_num - train_num\r\n",
        "\r\n",
        "    np.random.seed(seed=7)\r\n",
        "    np.random.shuffle(ecg_samples)\r\n",
        "    train_samples = ecg_samples[:train_num]\r\n",
        "    val_samples = ecg_samples[train_num:train_num+val_num]\r\n",
        "    test_samples = ecg_samples[-test_num:]\r\n",
        "\r\n",
        "    np.random.seed(seed=7)\r\n",
        "    np.random.shuffle(ecg_labels)\r\n",
        "    train_labels = ecg_labels[:train_num]\r\n",
        "    val_labels = ecg_labels[train_num:train_num+val_num]\r\n",
        "    test_labels = ecg_labels[-test_num:]\r\n",
        "\r\n",
        "    return train_samples, train_labels, val_samples, val_labels, test_samples, test_labels \r\n",
        "\r\n",
        "train_samples, train_labels, val_samples, val_labels, test_samples, test_labels = split_data(ecg_samples, ecg_labels, 0.8, 0.12)\r\n",
        "print(f'There are {len(train_samples)} subjects in training dataset')\r\n",
        "print(f'There are {len(val_samples)} subjects in validation dataset')\r\n",
        "print(f'There are {len(test_samples)} subjects in testing dataset')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 18 subjects in training dataset\n",
            "There are 4 subjects in validation dataset\n",
            "There are 3 subjects in testing dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liakZ4jYL7c7"
      },
      "source": [
        "def preprocess_data(num_epoch, epoch_duration, sf, ecg_samples, ecg_labels, oversample=True):\n",
        "    \"\"\"\n",
        "    preprocess data with the matched dimension for training\n",
        "    [num_epoch, 30*sampling_frequency, 1]\n",
        "\n",
        "    params:\n",
        "    epoch - number of epoches for each training sample\n",
        "    sf - sampling frequency of ECG signal\n",
        "    file_path - file path of raw EDF file\n",
        "    \"\"\"\n",
        "    model_signal_input = []\n",
        "    model_label_input = []\n",
        "\n",
        "    num_of_sample_per_epoch = sf * epoch_duration\n",
        "\n",
        "    for i in range(len(ecg_samples)):\n",
        "        ecg_samples[i] = sklearn.preprocessing.minmax_scale(ecg_samples[i])\n",
        "        if oversample:\n",
        "            overlap = int(0.9 * num_epoch)\n",
        "            for j in range(len(ecg_samples[i])):\n",
        "                signal_segment = np.asarray(ecg_samples[i][j*(num_epoch - overlap): j*(num_epoch - overlap) + num_epoch])\n",
        "                if len(signal_segment) == num_epoch:\n",
        "                    new_signal_seg = np.reshape(signal_segment, (num_epoch, num_of_sample_per_epoch, 1))\n",
        "                    model_signal_input.append(new_signal_seg)\n",
        "                \n",
        "                # apply to labels as well\n",
        "                label_segment = np.asarray(ecg_labels[i][j*(num_epoch - overlap): j*(num_epoch - overlap) + num_epoch])\n",
        "                if len(label_segment) == num_epoch:\n",
        "                    model_label_input.append(label_segment)\n",
        "        \n",
        "        else:\n",
        "            for j in range(len(ecg_samples[i])):\n",
        "                signal_segment = np.asarray(ecg_samples[i][j*num_epoch: (j+1)*num_epoch]) \n",
        "                if len(signal_segment) == num_epoch:\n",
        "                    new_signal_seg = np.reshape(signal_segment, (num_epoch, num_of_sample_per_epoch, 1))\n",
        "                    model_signal_input.append(new_signal_seg)\n",
        "\n",
        "                # apply to labels as well\n",
        "                label_segment = np.asarray(ecg_labels[i][j*num_epoch: (j+1)*num_epoch])\n",
        "                if len(label_segment) == num_epoch:\n",
        "                    model_label_input.append(label_segment)\n",
        "        \n",
        "    print(f'shape of processed signal data: {np.asarray(model_signal_input).shape}')\n",
        "    print(f'shape of processed label data: {np.asarray(model_label_input).shape}')\n",
        "\n",
        "    return np.asarray(model_signal_input), np.asarray(model_label_input)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_sRNpmNbsjB",
        "outputId": "ed2f2c04-c534-4862-891d-c4aa597b5bd0"
      },
      "source": [
        "train_signal_input, train_label_input = preprocess_data(50, 30, 128, train_samples, train_labels, oversample=True)\r\n",
        "val_signal_input, val_label_input = preprocess_data(50, 30, 128, val_samples, val_labels, oversample=True)\r\n",
        "test_signal_input, test_label_input = preprocess_data(50, 30, 128, test_samples, test_labels, oversample=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of processed signal data: (2808, 50, 3840, 1)\n",
            "shape of processed label data: (2808, 50)\n",
            "shape of processed signal data: (642, 50, 3840, 1)\n",
            "shape of processed label data: (642, 50)\n",
            "shape of processed signal data: (49, 50, 3840, 1)\n",
            "shape of processed label data: (49, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To0oFayj-AWy",
        "outputId": "ca49cc0d-36d9-4c01-97d8-65292fd9e2f6"
      },
      "source": [
        "def helper(samples, labels):\r\n",
        "    for i in range(len(samples)):\r\n",
        "        print(f'{len(samples[i])}, {len(labels[i])}')\r\n",
        "\r\n",
        "helper(ecg_samples, ecg_labels)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "882, 882\n",
            "768, 768\n",
            "774, 774\n",
            "789, 789\n",
            "826, 826\n",
            "711, 711\n",
            "864, 864\n",
            "752, 752\n",
            "916, 916\n",
            "748, 748\n",
            "893, 893\n",
            "925, 925\n",
            "908, 908\n",
            "913, 913\n",
            "721, 721\n",
            "811, 811\n",
            "787, 787\n",
            "900, 900\n",
            "822, 822\n",
            "907, 907\n",
            "861, 861\n",
            "808, 808\n",
            "838, 838\n",
            "813, 813\n",
            "852, 852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o362XJUmsMHa",
        "outputId": "a145ecac-6125-4806-f9e6-41c636291892"
      },
      "source": [
        "def print_label(label_input):\r\n",
        "    print(f'There are {len(label_input[label_input == 0])} wake labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 1])} REM labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 2])} Stage_1 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 3])} Stage_2 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 4])} Stage_3 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 5])} Stage_4 labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 6])} Artifact labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 7])} Indeterminate labels \\n')\r\n",
        "\r\n",
        "print_label(train_label_input)\r\n",
        "print_label(val_label_input)\r\n",
        "print_label(test_label_input)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 30608 wake labels\n",
            "There are 19753 REM labels\n",
            "There are 25226 Stage_1 labels\n",
            "There are 48120 Stage_2 labels\n",
            "There are 4476 Stage_3 labels\n",
            "There are 12083 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n",
            "There are 6510 wake labels\n",
            "There are 4283 REM labels\n",
            "There are 5639 Stage_1 labels\n",
            "There are 10350 Stage_2 labels\n",
            "There are 1018 Stage_3 labels\n",
            "There are 4300 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n",
            "There are 256 wake labels\n",
            "There are 536 REM labels\n",
            "There are 189 Stage_1 labels\n",
            "There are 1007 Stage_2 labels\n",
            "There are 115 Stage_3 labels\n",
            "There are 347 Stage_4 labels\n",
            "There are 0 Artifact labels\n",
            "There are 0 Indeterminate labels \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBhTjlajO0JY"
      },
      "source": [
        "def join_labels(label_input):\r\n",
        "    for i in range(len(label_input)):\r\n",
        "        label_input[label_input > 1] = 2\r\n",
        "    print(f'There are {len(label_input[label_input == 0])} wake labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 1])} REM labels')\r\n",
        "    print(f'There are {len(label_input[label_input == 2])} NREM labels \\n')\r\n",
        "    return label_input"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfBTo1DySxHh",
        "outputId": "c832aff1-fe39-4579-ffbf-fa4ce43a073c"
      },
      "source": [
        "train_label_input_join = join_labels(train_label_input)\r\n",
        "val_label_input_join = join_labels(val_label_input)\r\n",
        "test_label_input_join = join_labels(test_label_input)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 30608 wake labels\n",
            "There are 19753 REM labels\n",
            "There are 90039 NREM labels \n",
            "\n",
            "There are 6510 wake labels\n",
            "There are 4283 REM labels\n",
            "There are 21307 NREM labels \n",
            "\n",
            "There are 256 wake labels\n",
            "There are 536 REM labels\n",
            "There are 1658 NREM labels \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XeavEnYttea"
      },
      "source": [
        "def oversample_label(signal_input, label_input_join):\r\n",
        "    os_signal_input = []\r\n",
        "    os_label_input_join = []\r\n",
        "    \r\n",
        "    for i in range(len(label_input_join)):\r\n",
        "        if len(label_input_join[i][label_input_join[i] == 1]) > 20:\r\n",
        "            for _ in range(4):\r\n",
        "                os_signal_input.append(signal_input[i])\r\n",
        "                os_label_input_join.append(label_input_join[i])\r\n",
        "        \r\n",
        "        os_signal_input.append(signal_input[i])\r\n",
        "        os_label_input_join.append(label_input_join[i])\r\n",
        "\r\n",
        "    os_signal = np.asarray(os_signal_input)\r\n",
        "    os_label = np.asarray(os_label_input_join)\r\n",
        "\r\n",
        "    print(f'There are {len(os_label[os_label == 0])} wake labels')\r\n",
        "    print(f'There are {len(os_label[os_label == 1])} REM labels')\r\n",
        "    print(f'There are {len(os_label[os_label == 2])} NREM labels \\n')\r\n",
        "    print(f'shape of input signal {os_signal.shape}')\r\n",
        "    print(f'shape of input label {os_label.shape} \\n')\r\n",
        "\r\n",
        "    return os_signal, os_label"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3dPkbW9vRhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1987abc4-8d1c-455b-8102-6fea78b6e81e"
      },
      "source": [
        "os_train_signal, os_train_label = oversample_label(train_signal_input, train_label_input_join)\r\n",
        "os_val_signal, os_val_label = oversample_label(val_signal_input, val_label_input_join)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 35188 wake labels\n",
            "There are 81493 REM labels\n",
            "There are 112719 NREM labels \n",
            "\n",
            "shape of input signal (4588, 50, 3840, 1)\n",
            "shape of input label (4588, 50) \n",
            "\n",
            "There are 7550 wake labels\n",
            "There are 17471 REM labels\n",
            "There are 25279 NREM labels \n",
            "\n",
            "shape of input signal (1006, 50, 3840, 1)\n",
            "shape of input label (1006, 50) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcFDcYX61O72"
      },
      "source": [
        "#3.Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvRMtVPTyE5"
      },
      "source": [
        "##3.1 Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr7CnSvMTqvF"
      },
      "source": [
        "## tensorboard callback\r\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "\r\n",
        "## checkpoint callback\r\n",
        "filepath = os.path.join(\"models\",  \"test-oversample-128Hz-{epoch:02d}-{loss:.4f}\")\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \r\n",
        "                             save_best_only=True, mode='auto')\r\n",
        "\r\n",
        "## early stop\r\n",
        "def decay(epoch):\r\n",
        "    if epoch < 50:\r\n",
        "        return 1e-3\r\n",
        "    elif 50 <= epoch < 150:\r\n",
        "        return 1e-4\r\n",
        "    else:\r\n",
        "        return 1e-5\r\n",
        "\r\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, \r\n",
        "                                              restore_best_weights=True)\r\n",
        "\r\n",
        "## learning rate decay callback\r\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)\r\n",
        "\r\n",
        "callbacks_list = [tensorboard_callback, checkpoint, early_stop, lr_schedule]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4t-6PrNT1I5"
      },
      "source": [
        "##3.2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxDhnq-R2AOW"
      },
      "source": [
        "###3.2.1 CNN+LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipW3enoc04qm"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((os_train_signal, os_train_label))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_signal_input, val_label_input_join))\n",
        "\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(1024).repeat().batch(batch_size, drop_remainder=True)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.repeat().batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltJxzYIr3i3v"
      },
      "source": [
        "def cnn_1d(input_shape=None, dropout=0.2):\r\n",
        "    \r\n",
        "    x_input = Input(shape=input_shape)\r\n",
        "    x = Conv1D(64, 21, strides=5, activation='relu')(x_input)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 2nd Conv1D\r\n",
        "    x = Conv1D(128, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 3rd Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 4th Conv1D\r\n",
        "    x = Conv1D(512, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 5th Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    # Full connection layer\r\n",
        "    out = Flatten()(x)\r\n",
        "\r\n",
        "    model = Model(x_input, out, name='cnn_1d_layer')\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qU6oB2U5Nvw",
        "outputId": "b3a7f9d7-799e-41be-f70c-1f62effabb46"
      },
      "source": [
        "def cnn_lstm(input_shape=(50,3840,1), classes=3):\r\n",
        "    cnn = cnn_1d((3840,1))\r\n",
        "    x_input = Input(shape=input_shape)\r\n",
        "    x = TimeDistributed(cnn)(x_input)\r\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\r\n",
        "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\r\n",
        "    out = TimeDistributed(Dense(classes))(x)\r\n",
        "    model = Model(x_input, out, name='cnn_lstm')\r\n",
        "\r\n",
        "    return model\r\n",
        "\r\n",
        "model = cnn_lstm(input_shape=(50,3840,1), classes=3)\r\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_lstm\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 50, 3840, 1)]     0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 50, 10240)         1522944   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 128)           5276160   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 50, 64)            41216     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 3)             195       \n",
            "=================================================================\n",
            "Total params: 6,840,515\n",
            "Trainable params: 6,838,083\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHvDHOP02EkZ"
      },
      "source": [
        "###3.2.2 Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmQ0QUIsVGF1"
      },
      "source": [
        "n_a = 32 #Number of pre-LSTM states\n",
        "n_s = 64 #Number of post-LSTM states\n",
        "Tx = 50\n",
        "Ty = 50\n",
        "t_s0 = np.zeros((len(os_train_signal), n_s))\n",
        "t_c0 = np.zeros((len(os_train_signal), n_s))\n",
        "v_s0 = np.zeros((len(os_val_signal), n_s))\n",
        "v_c0 = np.zeros((len(os_val_signal), n_s))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kjXiACEkGoY"
      },
      "source": [
        "repeator = RepeatVector(Tx) \r\n",
        "concatenator = Concatenate(axis=-1) \r\n",
        "densor1 = Dense(10, activation = \"tanh\") \r\n",
        "densor2 = Dense(1, activation = \"relu\")\r\n",
        "activator = Softmax(axis=1, name='attention_weights') \r\n",
        "dotor = Dot(axes = 1) \r\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\r\n",
        "output_layer = Dense(3)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9zWqn4J7IkH"
      },
      "source": [
        "def cnn_1d(input_shape=None, dropout=0.2):\r\n",
        "    \r\n",
        "    x_input = Input(shape=input_shape)\r\n",
        "    x = Conv1D(64, 21, strides=5, activation='relu')(x_input)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 2nd Conv1D\r\n",
        "    x = Conv1D(128, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 3rd Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 4th Conv1D\r\n",
        "    x = Conv1D(512, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = MaxPooling1D(pool_size=2, strides=2)(x)\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "    # 5th Conv1D\r\n",
        "    x = Conv1D(256, 5, strides=1, activation='relu')(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "\r\n",
        "    # Full connection layer\r\n",
        "    out = Flatten()(x)\r\n",
        "\r\n",
        "    model = Model(x_input, out, name='cnn_1d_layer')\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dPPH0IXkUG4"
      },
      "source": [
        "def one_step_attention(a, s_prev):\r\n",
        "    \"\"\"\r\n",
        "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\r\n",
        "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\r\n",
        "    \r\n",
        "    Arguments:\r\n",
        "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\r\n",
        "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "    context -- context vector, input of the next (post-attetion) LSTM cell\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    s_prev = repeator(s_prev)\r\n",
        "    concat = concatenator([a,s_prev])\r\n",
        "    e = densor1(concat)\r\n",
        "    energies = densor2(e)\r\n",
        "    alphas = activator(energies)\r\n",
        "    context = dotor([alphas,a])\r\n",
        "    return context"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lesW9zTykY5y"
      },
      "source": [
        "def cnn_attention(Tx, Ty, n_a, n_s, input_image_size, classes):\r\n",
        "    \"\"\"\r\n",
        "    Arguments:\r\n",
        "    Tx -- length of the input sequence\r\n",
        "    Ty -- length of the output sequence\r\n",
        "    n_a -- hidden state size of the Bi-LSTM\r\n",
        "    n_s -- hidden state size of the post-attention LSTM\r\n",
        "    input_image_size -- size of the 30s ECG samples\r\n",
        "    classes -- number of classes\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    model -- Keras model instance\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    X_input = Input(shape=(Tx, input_image_size, 1))\r\n",
        "    cnn = cnn_1d((3840,1))\r\n",
        "    X = TimeDistributed(cnn)(X_input)\r\n",
        "\r\n",
        "    s0 = Input(shape=(n_s,), name='s0')\r\n",
        "    c0 = Input(shape=(n_s,), name='c0')\r\n",
        "    s = s0\r\n",
        "    c = c0\r\n",
        "    \r\n",
        "    # Initialize empty list of outputs\r\n",
        "    outputs = []\r\n",
        "    \r\n",
        "    \r\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\r\n",
        "    \r\n",
        "    for t in range(Ty):\r\n",
        "    \r\n",
        "        context = one_step_attention(a, s)\r\n",
        "\r\n",
        "        s, _, c = post_activation_LSTM_cell(context,initial_state=[s, c])\r\n",
        "        \r\n",
        "        out = output_layer(s)\r\n",
        "                \r\n",
        "        outputs.append(out)\r\n",
        "    \r\n",
        "    \r\n",
        "    model = Model(inputs=[X_input, s0, c0], outputs=outputs)\r\n",
        "        \r\n",
        "    return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42VUjlUkkdQg"
      },
      "source": [
        "model = cnn_attention(Tx, Ty, n_a, n_s, 3840, 3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3loV3KmvkvVX",
        "outputId": "cfa32179-433a-4c40-aa66-4d80af992057"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 50, 3840, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 50, 10240)    1522944     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 50, 64)       2629888     time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 50, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[9][0]                       \n",
            "                                                                 lstm[10][0]                      \n",
            "                                                                 lstm[11][0]                      \n",
            "                                                                 lstm[12][0]                      \n",
            "                                                                 lstm[13][0]                      \n",
            "                                                                 lstm[14][0]                      \n",
            "                                                                 lstm[15][0]                      \n",
            "                                                                 lstm[16][0]                      \n",
            "                                                                 lstm[17][0]                      \n",
            "                                                                 lstm[18][0]                      \n",
            "                                                                 lstm[19][0]                      \n",
            "                                                                 lstm[20][0]                      \n",
            "                                                                 lstm[21][0]                      \n",
            "                                                                 lstm[22][0]                      \n",
            "                                                                 lstm[23][0]                      \n",
            "                                                                 lstm[24][0]                      \n",
            "                                                                 lstm[25][0]                      \n",
            "                                                                 lstm[26][0]                      \n",
            "                                                                 lstm[27][0]                      \n",
            "                                                                 lstm[28][0]                      \n",
            "                                                                 lstm[29][0]                      \n",
            "                                                                 lstm[30][0]                      \n",
            "                                                                 lstm[31][0]                      \n",
            "                                                                 lstm[32][0]                      \n",
            "                                                                 lstm[33][0]                      \n",
            "                                                                 lstm[34][0]                      \n",
            "                                                                 lstm[35][0]                      \n",
            "                                                                 lstm[36][0]                      \n",
            "                                                                 lstm[37][0]                      \n",
            "                                                                 lstm[38][0]                      \n",
            "                                                                 lstm[39][0]                      \n",
            "                                                                 lstm[40][0]                      \n",
            "                                                                 lstm[41][0]                      \n",
            "                                                                 lstm[42][0]                      \n",
            "                                                                 lstm[43][0]                      \n",
            "                                                                 lstm[44][0]                      \n",
            "                                                                 lstm[45][0]                      \n",
            "                                                                 lstm[46][0]                      \n",
            "                                                                 lstm[47][0]                      \n",
            "                                                                 lstm[48][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 50, 128)      0           bidirectional[0][0]              \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[19][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[20][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[21][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[22][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[23][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[24][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[25][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[26][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[27][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[28][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[29][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[30][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[31][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[32][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[33][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[34][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[35][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[36][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[37][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[38][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[39][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[40][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[41][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[42][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[43][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[44][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[45][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[46][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[47][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[48][0]             \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[49][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50, 10)       1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[19][0]               \n",
            "                                                                 concatenate[20][0]               \n",
            "                                                                 concatenate[21][0]               \n",
            "                                                                 concatenate[22][0]               \n",
            "                                                                 concatenate[23][0]               \n",
            "                                                                 concatenate[24][0]               \n",
            "                                                                 concatenate[25][0]               \n",
            "                                                                 concatenate[26][0]               \n",
            "                                                                 concatenate[27][0]               \n",
            "                                                                 concatenate[28][0]               \n",
            "                                                                 concatenate[29][0]               \n",
            "                                                                 concatenate[30][0]               \n",
            "                                                                 concatenate[31][0]               \n",
            "                                                                 concatenate[32][0]               \n",
            "                                                                 concatenate[33][0]               \n",
            "                                                                 concatenate[34][0]               \n",
            "                                                                 concatenate[35][0]               \n",
            "                                                                 concatenate[36][0]               \n",
            "                                                                 concatenate[37][0]               \n",
            "                                                                 concatenate[38][0]               \n",
            "                                                                 concatenate[39][0]               \n",
            "                                                                 concatenate[40][0]               \n",
            "                                                                 concatenate[41][0]               \n",
            "                                                                 concatenate[42][0]               \n",
            "                                                                 concatenate[43][0]               \n",
            "                                                                 concatenate[44][0]               \n",
            "                                                                 concatenate[45][0]               \n",
            "                                                                 concatenate[46][0]               \n",
            "                                                                 concatenate[47][0]               \n",
            "                                                                 concatenate[48][0]               \n",
            "                                                                 concatenate[49][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[19][0]                     \n",
            "                                                                 dense[20][0]                     \n",
            "                                                                 dense[21][0]                     \n",
            "                                                                 dense[22][0]                     \n",
            "                                                                 dense[23][0]                     \n",
            "                                                                 dense[24][0]                     \n",
            "                                                                 dense[25][0]                     \n",
            "                                                                 dense[26][0]                     \n",
            "                                                                 dense[27][0]                     \n",
            "                                                                 dense[28][0]                     \n",
            "                                                                 dense[29][0]                     \n",
            "                                                                 dense[30][0]                     \n",
            "                                                                 dense[31][0]                     \n",
            "                                                                 dense[32][0]                     \n",
            "                                                                 dense[33][0]                     \n",
            "                                                                 dense[34][0]                     \n",
            "                                                                 dense[35][0]                     \n",
            "                                                                 dense[36][0]                     \n",
            "                                                                 dense[37][0]                     \n",
            "                                                                 dense[38][0]                     \n",
            "                                                                 dense[39][0]                     \n",
            "                                                                 dense[40][0]                     \n",
            "                                                                 dense[41][0]                     \n",
            "                                                                 dense[42][0]                     \n",
            "                                                                 dense[43][0]                     \n",
            "                                                                 dense[44][0]                     \n",
            "                                                                 dense[45][0]                     \n",
            "                                                                 dense[46][0]                     \n",
            "                                                                 dense[47][0]                     \n",
            "                                                                 dense[48][0]                     \n",
            "                                                                 dense[49][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Softmax)     (None, 50, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 dense_1[19][0]                   \n",
            "                                                                 dense_1[20][0]                   \n",
            "                                                                 dense_1[21][0]                   \n",
            "                                                                 dense_1[22][0]                   \n",
            "                                                                 dense_1[23][0]                   \n",
            "                                                                 dense_1[24][0]                   \n",
            "                                                                 dense_1[25][0]                   \n",
            "                                                                 dense_1[26][0]                   \n",
            "                                                                 dense_1[27][0]                   \n",
            "                                                                 dense_1[28][0]                   \n",
            "                                                                 dense_1[29][0]                   \n",
            "                                                                 dense_1[30][0]                   \n",
            "                                                                 dense_1[31][0]                   \n",
            "                                                                 dense_1[32][0]                   \n",
            "                                                                 dense_1[33][0]                   \n",
            "                                                                 dense_1[34][0]                   \n",
            "                                                                 dense_1[35][0]                   \n",
            "                                                                 dense_1[36][0]                   \n",
            "                                                                 dense_1[37][0]                   \n",
            "                                                                 dense_1[38][0]                   \n",
            "                                                                 dense_1[39][0]                   \n",
            "                                                                 dense_1[40][0]                   \n",
            "                                                                 dense_1[41][0]                   \n",
            "                                                                 dense_1[42][0]                   \n",
            "                                                                 dense_1[43][0]                   \n",
            "                                                                 dense_1[44][0]                   \n",
            "                                                                 dense_1[45][0]                   \n",
            "                                                                 dense_1[46][0]                   \n",
            "                                                                 dense_1[47][0]                   \n",
            "                                                                 dense_1[48][0]                   \n",
            "                                                                 dense_1[49][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 64)        0           attention_weights[0][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[1][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[2][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[3][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[4][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[5][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[6][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[7][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[8][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[9][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[10][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[11][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[12][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[13][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[14][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[15][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[16][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[17][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[18][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[19][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[20][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[21][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[22][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[23][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[24][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[25][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[26][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[27][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[28][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[29][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[30][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[31][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[32][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[33][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[34][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[35][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[36][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[37][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[38][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[39][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[40][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[41][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[42][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[43][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[44][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[45][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[46][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[47][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[48][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[49][0]         \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 64), (None,  33024       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[1][2]                       \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[2][2]                       \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[3][2]                       \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[4][2]                       \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[5][2]                       \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[6][2]                       \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[7][2]                       \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[8][2]                       \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 lstm[9][0]                       \n",
            "                                                                 lstm[9][2]                       \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 lstm[10][0]                      \n",
            "                                                                 lstm[10][2]                      \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 lstm[11][0]                      \n",
            "                                                                 lstm[11][2]                      \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 lstm[12][0]                      \n",
            "                                                                 lstm[12][2]                      \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 lstm[13][0]                      \n",
            "                                                                 lstm[13][2]                      \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 lstm[14][0]                      \n",
            "                                                                 lstm[14][2]                      \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 lstm[15][0]                      \n",
            "                                                                 lstm[15][2]                      \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 lstm[16][0]                      \n",
            "                                                                 lstm[16][2]                      \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 lstm[17][0]                      \n",
            "                                                                 lstm[17][2]                      \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 lstm[18][0]                      \n",
            "                                                                 lstm[18][2]                      \n",
            "                                                                 dot[20][0]                       \n",
            "                                                                 lstm[19][0]                      \n",
            "                                                                 lstm[19][2]                      \n",
            "                                                                 dot[21][0]                       \n",
            "                                                                 lstm[20][0]                      \n",
            "                                                                 lstm[20][2]                      \n",
            "                                                                 dot[22][0]                       \n",
            "                                                                 lstm[21][0]                      \n",
            "                                                                 lstm[21][2]                      \n",
            "                                                                 dot[23][0]                       \n",
            "                                                                 lstm[22][0]                      \n",
            "                                                                 lstm[22][2]                      \n",
            "                                                                 dot[24][0]                       \n",
            "                                                                 lstm[23][0]                      \n",
            "                                                                 lstm[23][2]                      \n",
            "                                                                 dot[25][0]                       \n",
            "                                                                 lstm[24][0]                      \n",
            "                                                                 lstm[24][2]                      \n",
            "                                                                 dot[26][0]                       \n",
            "                                                                 lstm[25][0]                      \n",
            "                                                                 lstm[25][2]                      \n",
            "                                                                 dot[27][0]                       \n",
            "                                                                 lstm[26][0]                      \n",
            "                                                                 lstm[26][2]                      \n",
            "                                                                 dot[28][0]                       \n",
            "                                                                 lstm[27][0]                      \n",
            "                                                                 lstm[27][2]                      \n",
            "                                                                 dot[29][0]                       \n",
            "                                                                 lstm[28][0]                      \n",
            "                                                                 lstm[28][2]                      \n",
            "                                                                 dot[30][0]                       \n",
            "                                                                 lstm[29][0]                      \n",
            "                                                                 lstm[29][2]                      \n",
            "                                                                 dot[31][0]                       \n",
            "                                                                 lstm[30][0]                      \n",
            "                                                                 lstm[30][2]                      \n",
            "                                                                 dot[32][0]                       \n",
            "                                                                 lstm[31][0]                      \n",
            "                                                                 lstm[31][2]                      \n",
            "                                                                 dot[33][0]                       \n",
            "                                                                 lstm[32][0]                      \n",
            "                                                                 lstm[32][2]                      \n",
            "                                                                 dot[34][0]                       \n",
            "                                                                 lstm[33][0]                      \n",
            "                                                                 lstm[33][2]                      \n",
            "                                                                 dot[35][0]                       \n",
            "                                                                 lstm[34][0]                      \n",
            "                                                                 lstm[34][2]                      \n",
            "                                                                 dot[36][0]                       \n",
            "                                                                 lstm[35][0]                      \n",
            "                                                                 lstm[35][2]                      \n",
            "                                                                 dot[37][0]                       \n",
            "                                                                 lstm[36][0]                      \n",
            "                                                                 lstm[36][2]                      \n",
            "                                                                 dot[38][0]                       \n",
            "                                                                 lstm[37][0]                      \n",
            "                                                                 lstm[37][2]                      \n",
            "                                                                 dot[39][0]                       \n",
            "                                                                 lstm[38][0]                      \n",
            "                                                                 lstm[38][2]                      \n",
            "                                                                 dot[40][0]                       \n",
            "                                                                 lstm[39][0]                      \n",
            "                                                                 lstm[39][2]                      \n",
            "                                                                 dot[41][0]                       \n",
            "                                                                 lstm[40][0]                      \n",
            "                                                                 lstm[40][2]                      \n",
            "                                                                 dot[42][0]                       \n",
            "                                                                 lstm[41][0]                      \n",
            "                                                                 lstm[41][2]                      \n",
            "                                                                 dot[43][0]                       \n",
            "                                                                 lstm[42][0]                      \n",
            "                                                                 lstm[42][2]                      \n",
            "                                                                 dot[44][0]                       \n",
            "                                                                 lstm[43][0]                      \n",
            "                                                                 lstm[43][2]                      \n",
            "                                                                 dot[45][0]                       \n",
            "                                                                 lstm[44][0]                      \n",
            "                                                                 lstm[44][2]                      \n",
            "                                                                 dot[46][0]                       \n",
            "                                                                 lstm[45][0]                      \n",
            "                                                                 lstm[45][2]                      \n",
            "                                                                 dot[47][0]                       \n",
            "                                                                 lstm[46][0]                      \n",
            "                                                                 lstm[46][2]                      \n",
            "                                                                 dot[48][0]                       \n",
            "                                                                 lstm[47][0]                      \n",
            "                                                                 lstm[47][2]                      \n",
            "                                                                 dot[49][0]                       \n",
            "                                                                 lstm[48][0]                      \n",
            "                                                                 lstm[48][2]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            195         lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[9][0]                       \n",
            "                                                                 lstm[10][0]                      \n",
            "                                                                 lstm[11][0]                      \n",
            "                                                                 lstm[12][0]                      \n",
            "                                                                 lstm[13][0]                      \n",
            "                                                                 lstm[14][0]                      \n",
            "                                                                 lstm[15][0]                      \n",
            "                                                                 lstm[16][0]                      \n",
            "                                                                 lstm[17][0]                      \n",
            "                                                                 lstm[18][0]                      \n",
            "                                                                 lstm[19][0]                      \n",
            "                                                                 lstm[20][0]                      \n",
            "                                                                 lstm[21][0]                      \n",
            "                                                                 lstm[22][0]                      \n",
            "                                                                 lstm[23][0]                      \n",
            "                                                                 lstm[24][0]                      \n",
            "                                                                 lstm[25][0]                      \n",
            "                                                                 lstm[26][0]                      \n",
            "                                                                 lstm[27][0]                      \n",
            "                                                                 lstm[28][0]                      \n",
            "                                                                 lstm[29][0]                      \n",
            "                                                                 lstm[30][0]                      \n",
            "                                                                 lstm[31][0]                      \n",
            "                                                                 lstm[32][0]                      \n",
            "                                                                 lstm[33][0]                      \n",
            "                                                                 lstm[34][0]                      \n",
            "                                                                 lstm[35][0]                      \n",
            "                                                                 lstm[36][0]                      \n",
            "                                                                 lstm[37][0]                      \n",
            "                                                                 lstm[38][0]                      \n",
            "                                                                 lstm[39][0]                      \n",
            "                                                                 lstm[40][0]                      \n",
            "                                                                 lstm[41][0]                      \n",
            "                                                                 lstm[42][0]                      \n",
            "                                                                 lstm[43][0]                      \n",
            "                                                                 lstm[44][0]                      \n",
            "                                                                 lstm[45][0]                      \n",
            "                                                                 lstm[46][0]                      \n",
            "                                                                 lstm[47][0]                      \n",
            "                                                                 lstm[48][0]                      \n",
            "                                                                 lstm[49][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,187,352\n",
            "Trainable params: 4,184,920\n",
            "Non-trainable params: 2,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kbNKcqp16t1"
      },
      "source": [
        "##3.3 Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPhi6yWq-QSc"
      },
      "source": [
        "class CustomizedLoss(tf.keras.losses.Loss):\r\n",
        "    def compute_loss(self, logits, positions):\r\n",
        "        one_hot_positions = tf.one_hot(\r\n",
        "            int(positions), depth=3)\r\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\r\n",
        "        weight = tf.constant([1.,4.,1.])\r\n",
        "        loss = -tf.reduce_mean(\r\n",
        "            tf.reduce_sum(one_hot_positions * log_probs * weight, axis=-1))\r\n",
        "        return loss\r\n",
        "    \r\n",
        "    def call(self, y_true, y_pred):\r\n",
        "        loss = self.compute_loss(y_pred, y_true)\r\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFQivnnfhnfd"
      },
      "source": [
        "###3.3.1 Train with distributed TPUs/GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6zyZWwd68Cl"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyM3gkryf8bg"
      },
      "source": [
        "with mirrored_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\r\n",
        "    \r\n",
        "    batch_size = 16\r\n",
        "    repeator = RepeatVector(Tx) \r\n",
        "    concatenator = Concatenate(axis=-1) \r\n",
        "    densor1 = Dense(10, activation = \"tanh\") \r\n",
        "    densor2 = Dense(1, activation = \"relu\")\r\n",
        "    activator = Softmax(axis=1, name='attention_weights') \r\n",
        "    dotor = Dot(axes = 1)\r\n",
        "\r\n",
        "    post_activation_LSTM_cell = LSTM(n_s, return_state = True)\r\n",
        "    output_layer = Dense(3)\r\n",
        "\r\n",
        "    model = cnn_attention(Tx, Ty, n_a, n_s, 3840, 3)\r\n",
        "    \r\n",
        "    ## tensorboard callback\r\n",
        "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\r\n",
        "    ## early stop\r\n",
        "    def decay(epoch):\r\n",
        "        if epoch < 50:\r\n",
        "            return 1e-4\r\n",
        "        elif 50 <= epoch < 150:\r\n",
        "            return 1e-5\r\n",
        "        else:\r\n",
        "            return 1e-6\r\n",
        "\r\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\r\n",
        "\r\n",
        "    ## learning rate decay callback\r\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(decay)\r\n",
        "\r\n",
        "    callbacks_list = [tensorboard_callback, early_stop, lr_schedule]\r\n",
        "\r\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    \r\n",
        "    history = model.fit(x=[os_train_signal, t_s0, t_c0],\r\n",
        "                        y=list(os_train_label.swapaxes(0,1)),\r\n",
        "                        epochs=100,\r\n",
        "                        batch_size=16,\r\n",
        "                        steps_per_epoch=len(os_train_signal)//batch_size,\r\n",
        "                        verbose=1,\r\n",
        "                        validation_data=([os_val_signal, v_s0, v_c0], \r\n",
        "                                         list(os_val_label.swapaxes(0,1))),\r\n",
        "                        validation_batch_size=16,\r\n",
        "                        validation_steps=len(os_val_signal)//batch_size,\r\n",
        "                        callbacks=callbacks_list\r\n",
        "                        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "h9bz4jNaH8jG",
        "outputId": "02b3677d-9584-4fa1-956b-f9f8b1198385"
      },
      "source": [
        "# Retrieve a list of list results on training and test data sets for each training epoch\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(loss)) # Get number of epochs\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\")\n",
        "plt.title('Training and validation Loss')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-6f94d4911b69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retrieve a list of list results on training and test data sets for each training epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUee80JIhjyY"
      },
      "source": [
        "###3.3.2 Train with single TPU/GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsdPxG-S4u6W"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkCRBVpfyoBs"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTUeyZ1hSNhf"
      },
      "source": [
        "from tensorboard import notebook\r\n",
        "notebook.display(port=6006, height=1000) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSaqMKILK74W"
      },
      "source": [
        "model.fit([os_train_signal, t_s0, t_c0],\r\n",
        "          list(os_train_label.swapaxes(0,1)),\r\n",
        "          epochs=100,\r\n",
        "          batch_size=10,\r\n",
        "          verbose=1,\r\n",
        "          callbacks=callbacks_list\r\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgz_Nsz5sCfg"
      },
      "source": [
        "#4.Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ASNC6pT0m-A"
      },
      "source": [
        "# make predcitions\r\n",
        "val_pred_raw = model.predict([os_val_signal, v_s0, v_c0])\r\n",
        "val_pred = np.argmax(val_pred_raw, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38nCyuTB0BpO"
      },
      "source": [
        "##4.1 Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY78rgfRsSTI"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names, normalize=False):\r\n",
        "    \"\"\"\r\n",
        "    Returns a matplotlib figure containing the plotted confusion matrix.\r\n",
        "\r\n",
        "    Args:\r\n",
        "       cm (array, shape = [n, n]): a confusion matrix of integer classes\r\n",
        "       class_names (array, shape = [n]): String names of the integer classes\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    figure = plt.figure(figsize=(8, 8))\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\r\n",
        "    plt.title(\"Confusion matrix\")\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(class_names))\r\n",
        "    plt.xticks(tick_marks, class_names)\r\n",
        "    plt.yticks(tick_marks, class_names)\r\n",
        "    plt.ylim(bottom=-0.5, top=2.5)\r\n",
        "\r\n",
        "    if normalize:\r\n",
        "        cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\r\n",
        "\r\n",
        "    # Use white text if squares are dark; otherwise black.\r\n",
        "    threshold = cm.max() / 1.5\r\n",
        "\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        color = \"white\" if cm[i, j] > threshold else \"black\"\r\n",
        "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "Ga9jFfrBvJvk",
        "outputId": "d5d01297-ac8e-41ec-d583-5e48dcec8a91"
      },
      "source": [
        "class_names = ['Wake','REM','NREM']\r\n",
        "cm = sklearn.metrics.confusion_matrix(val_label_input_join.flatten(), val_pred.flatten())\r\n",
        "plot_confusion_matrix(cm, class_names=class_names, normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1U84UqH0FHd"
      },
      "source": [
        "##4.2 Cohen’s kappa coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdcd9LD-0Wob",
        "outputId": "7c990ab4-1b2f-421a-8dee-687a529b7434"
      },
      "source": [
        "sklearn.metrics.cohen_kappa_score(val_label_input_join.flatten(), val_pred.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28901251808963335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsgNnBoI0338"
      },
      "source": [
        "##4.3 Clinical parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SawPaKLS0-mD"
      },
      "source": [
        "# total sleep time\r\n",
        "# sleep efficiency\r\n",
        "# sleep stage percentage\r\n",
        "# AHI"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}